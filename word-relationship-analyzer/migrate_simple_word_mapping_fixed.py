#!/usr/bin/env python3
"""
Simple word similarity migration - ONLY source_word_id and target_word_id.
No similarity scores or rule types as requested.
"""

import csv
import sys
import os
from supabase import create_client

# Supabase configuration
SUPABASE_URL = "https://ifgitxejnakfrfeiipkx.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImlmZ2l0eGVqbmFrZnJmZWlpcGt4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTY2ODQ3NjAsImV4cCI6MjA3MjI2MDc2MH0.aeUT8BnQOezCNjhVIwVQlxvoQnvCoh4TnjwuVbNjsEM"

def get_all_french_vocabulary_mapping(supabase):
    """Get ALL French vocabulary from the entire database"""
    print("ğŸ” Getting ALL French vocabulary from entire database...")
    print("=" * 60)
    
    try:
        # Get all vocabulary that could be French
        # Look for words with French characteristics (accents, common French patterns)
        french_patterns = ['Ã©', 'Ã¨', 'Ãª', 'Ã«', 'Ã ', 'Ã¢', 'Ã¤', 'Ã§', 'Ã®', 'Ã¯', 'Ã´', 'Ã¶', 'Ã¹', 'Ã»', 'Ã¼', 'Ã¿']
        
        print(f"ğŸ“Š Searching for French words with accent patterns...")
        
        # Get all vocabulary using pagination
        all_vocab_data = []
        page_size = 1000
        offset = 0
        
        while True:
            batch_result = supabase.table('vocabulary').select('id, language_a_word, language_b_translation').range(offset, offset + page_size - 1).execute()
            
            if not batch_result.data:
                break
                
            all_vocab_data.extend(batch_result.data)
            offset += page_size
            
            if len(batch_result.data) < page_size:
                break
        
        print(f"ğŸ“Š Retrieved {len(all_vocab_data)} vocabulary entries from database")
        
        if not all_vocab_data:
            print("âŒ No vocabulary found!")
            return {}
        
        print(f"ğŸ“Š Analyzing {len(all_vocab_data)} vocabulary entries...")
        
        # Find French words (words with French accents/patterns)
        french_words = []
        for vocab in all_vocab_data:
            word = vocab['language_a_word']
            if any(pattern in word for pattern in french_patterns):
                french_words.append(vocab)
        
        print(f"ğŸ‡«ğŸ‡· Found {len(french_words)} words with French accent patterns")
        
        # Create comprehensive word-to-ID mapping for ALL French words
        word_to_id = {}
        for vocab in french_words:
            french_word = vocab['language_a_word'].lower().strip()
            word_to_id[french_word] = vocab['id']
        
        print(f"âœ… Created comprehensive mapping for {len(word_to_id)} French words")
        
        # Show sample mapping
        print(f"\nğŸ“ Sample French word mappings:")
        sample_words = list(word_to_id.items())[:10]
        for word, vocab_id in sample_words:
            print(f"   '{word}' â†’ ID {vocab_id}")
        
        if len(word_to_id) > 10:
            print(f"   ... and {len(word_to_id) - 10} more")
        
        return word_to_id
        
    except Exception as e:
        print(f"âŒ Error getting French vocabulary: {e}")
        return {}

def migrate_simple_word_mapping():
    """Migrate word similarities - SIMPLE version with only source and target IDs"""
    print("ğŸš€ Starting SIMPLE word similarity migration...")
    print("=" * 60)
    print("ğŸ”’ GUARANTEE: Zero changes to existing data - only adds new relationships")
    print("ğŸ“ SIMPLE: Only source_word_id and target_word_id (no scores or rule types)")
    print("=" * 60)
    
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # Step 1: Get comprehensive French vocabulary mapping
    word_to_id = get_all_french_vocabulary_mapping(supabase)
    if not word_to_id:
        return False
    
    # Step 2: Process CSV similarities
    csv_file = 'consolidated_results/final_enhanced_french_similarities.csv'
    
    if not os.path.exists(csv_file):
        print(f"âŒ CSV file not found: {csv_file}")
        return False
    
    print(f"\nğŸ“ Processing similarities from: {csv_file}")
    
    # Track unique relationships
    unique_relationships = set()
    processed_count = 0
    skipped_count = 0
    error_count = 0
    total_relationships = 0
    
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                try:
                    target_word = row['target_word'].strip().lower()
                    similar_words_str = row['similar_words']
                    
                    if not target_word or not similar_words_str:
                        continue
                    
                    # Check if target word is in French vocabulary
                    if target_word not in word_to_id:
                        skipped_count += 1
                        if skipped_count <= 5:  # Show first 5 skipped words
                            print(f"âš ï¸  Skipping target word not in French vocabulary: {target_word}")
                        continue
                    
                    target_id = word_to_id[target_word]
                    print(f"ğŸ“ Target: {target_word} â†’ ID {target_id}")
                    
                    # Parse similar words
                    similar_words = [w.strip().lower() for w in similar_words_str.split(',') if w.strip()]
                    
                    # Create relationships for French words only
                    for similar_word in similar_words:
                        if similar_word not in word_to_id:
                            skipped_count += 1
                            continue
                        
                        similar_id = word_to_id[similar_word]
                        print(f"   ğŸ”— Similar: {similar_word} â†’ ID {similar_id}")
                        
                        # Create unique key for relationship
                        source_id = min(target_id, similar_id)
                        target_id_rel = max(target_id, similar_id)
                        
                        relationship_key = f"{source_id}-{target_id_rel}"
                        
                        # Only add if not already processed
                        if relationship_key not in unique_relationships:
                            # SIMPLE similarity data - only source and target IDs
                            similarity_data = {
                                'source_word_id': source_id,
                                'target_word_id': target_id_rel
                            }
                            
                            unique_relationships.add(relationship_key)
                            total_relationships += 1
                            
                            # Insert immediately into NEW table only
                            try:
                                result = supabase.table('word_similarities').upsert(
                                    similarity_data,
                                    on_conflict='source_word_id,target_word_id'
                                ).execute()
                                
                                print(f"   âœ… Created: {source_id} â†’ {target_id_rel}")
                                    
                            except Exception as e:
                                print(f"   âŒ Error inserting relationship: {e}")
                                error_count += 1
                    
                    processed_count += 1
                    print(f"ğŸ“Š Processed {processed_count} French words, {total_relationships} relationships\n")
                    
                    # Stop after processing a few examples to show the pattern
                    if processed_count >= 5:
                        print("ğŸ›‘ Stopping after 5 examples to show the mapping pattern...")
                        break
                        
                except Exception as e:
                    print(f"âŒ Error processing row {processed_count}: {e}")
                    error_count += 1
                    continue
        
        print("\n" + "=" * 60)
        print("ğŸ‰ Simple word similarity migration completed!")
        print(f"ğŸ“Š Summary:")
        print(f"   âœ… Processed {processed_count} French target words")
        print(f"   âš ï¸  Skipped {skipped_count} words not in French vocabulary")
        print(f"   âŒ Errors: {error_count}")
        print(f"   ğŸ”— Total unique relationships created: {total_relationships}")
        
        # Calculate success rate
        success_rate = (processed_count / (processed_count + skipped_count) * 100) if (processed_count + skipped_count) > 0 else 0
        print(f"   ğŸ“ˆ Success rate: {success_rate:.1f}%")
        
        # Verify migration results
        print(f"\nğŸ” Verifying migration results...")
        verify_result = supabase.table('word_similarities').select('*', count='exact').execute()
        if verify_result.count:
            print(f"   ğŸ“ˆ Total word similarity relationships: {verify_result.count}")
        
        print(f"\nğŸ”’ SAFETY CONFIRMATION:")
        print(f"   âœ… No existing vocabulary data was modified")
        print(f"   âœ… No existing deck data was modified")
        print(f"   âœ… No existing user progress was modified")
        print(f"   âœ… Only NEW relationships were added to word_similarities table")
        print(f"   âœ… SIMPLE structure: only source_word_id and target_word_id")
        
        return True
        
    except Exception as e:
        print(f"âŒ Fatal error during migration: {e}")
        return False

if __name__ == "__main__":
    success = migrate_simple_word_mapping()
    if success:
        print("\nğŸš€ Ready to continue with full migration!")
        print("ğŸ’¡ This shows the SIMPLE approach with only source and target word IDs.")
        print("ğŸ”„ Run with full processing to migrate all word similarities.")
        print("ğŸ”’ Your existing data remains completely unchanged!")
    else:
        print("\nğŸ”§ Please fix errors before proceeding.")
