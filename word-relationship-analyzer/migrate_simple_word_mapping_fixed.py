#!/usr/bin/env python3
"""
Simple word similarity migration - ONLY source_word_id and target_word_id.
No similarity scores or rule types as requested.
"""

import csv
import sys
import os
from supabase import create_client

# Supabase configuration
SUPABASE_URL = "https://ifgitxejnakfrfeiipkx.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImlmZ2l0eGVqbmFrZnJmZWlpcGt4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTY2ODQ3NjAsImV4cCI6MjA3MjI2MDc2MH0.aeUT8BnQOezCNjhVIwVQlxvoQnvCoh4TnjwuVbNjsEM"

def get_all_french_vocabulary_mapping(supabase):
    """Get ALL French vocabulary from the entire database"""
    print("üîç Getting ALL French vocabulary from entire database...")
    print("=" * 60)
    
    try:
        # Get all vocabulary that could be French
        # Look for words with French characteristics (accents, common French patterns)
        french_patterns = ['√©', '√®', '√™', '√´', '√†', '√¢', '√§', '√ß', '√Æ', '√Ø', '√¥', '√∂', '√π', '√ª', '√º', '√ø']
        
        print(f"üìä Searching for French words with accent patterns...")
        
        # Get all vocabulary using pagination
        all_vocab_data = []
        page_size = 1000
        offset = 0
        
        while True:
            batch_result = supabase.table('vocabulary').select('id, language_a_word, language_b_translation').range(offset, offset + page_size - 1).execute()
            
            if not batch_result.data:
                break
                
            all_vocab_data.extend(batch_result.data)
            offset += page_size
            
            if len(batch_result.data) < page_size:
                break
        
        print(f"üìä Retrieved {len(all_vocab_data)} vocabulary entries from database")
        
        if not all_vocab_data:
            print("‚ùå No vocabulary found!")
            return {}
        
        print(f"üìä Analyzing {len(all_vocab_data)} vocabulary entries...")
        
        # Find French words (words with French accents/patterns)
        french_words = []
        for vocab in all_vocab_data:
            word = vocab['language_a_word']
            if any(pattern in word for pattern in french_patterns):
                french_words.append(vocab)
        
        print(f"üá´üá∑ Found {len(french_words)} words with French accent patterns")
        
        # Create comprehensive word-to-ID mapping for ALL French words
        word_to_id = {}
        for vocab in french_words:
            french_word = vocab['language_a_word'].lower().strip()
            word_to_id[french_word] = vocab['id']
        
        print(f"‚úÖ Created comprehensive mapping for {len(word_to_id)} French words")
        
        # Show sample mapping
        print(f"\nüìù Sample French word mappings:")
        sample_words = list(word_to_id.items())[:10]
        for word, vocab_id in sample_words:
            print(f"   '{word}' ‚Üí ID {vocab_id}")
        
        if len(word_to_id) > 10:
            print(f"   ... and {len(word_to_id) - 10} more")
        
        return word_to_id
        
    except Exception as e:
        print(f"‚ùå Error getting French vocabulary: {e}")
        return {}

def migrate_simple_word_mapping():
    """Migrate word similarities - SIMPLE version with only source and target IDs"""
    print("üöÄ Starting SIMPLE word similarity migration...")
    print("=" * 60)
    print("üîí GUARANTEE: Zero changes to existing data - only adds new relationships")
    print("üìù SIMPLE: Only source_word_id and target_word_id (no scores or rule types)")
    print("=" * 60)
    
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # Step 1: Get comprehensive French vocabulary mapping
    word_to_id = get_all_french_vocabulary_mapping(supabase)
    if not word_to_id:
        return False
    
    # Step 2: Process CSV similarities
    csv_file = 'consolidated_results/final_enhanced_french_similarities.csv'
    
    if not os.path.exists(csv_file):
        print(f"‚ùå CSV file not found: {csv_file}")
        return False
    
    print(f"\nüìÅ Processing similarities from: {csv_file}")
    
    # Track unique relationships
    unique_relationships = set()
    processed_count = 0
    skipped_count = 0
    error_count = 0
    total_relationships = 0
    
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                try:
                    target_word = row['target_word'].strip().lower()
                    similar_words_str = row['similar_words']
                    
                    if not target_word or not similar_words_str:
                        continue
                    
                    # Check if target word is in French vocabulary
                    if target_word not in word_to_id:
                        skipped_count += 1
                        if skipped_count <= 5:  # Show first 5 skipped words
                            print(f"‚ö†Ô∏è  Skipping target word not in French vocabulary: {target_word}")
                        continue
                    
                    target_id = word_to_id[target_word]
                    print(f"üìç Target: {target_word} ‚Üí ID {target_id}")
                    
                    # Parse similar words
                    similar_words = [w.strip().lower() for w in similar_words_str.split(',') if w.strip()]
                    
                    # Create relationships for French words only
                    for similar_word in similar_words:
                        if similar_word not in word_to_id:
                            skipped_count += 1
                            continue
                        
                        similar_id = word_to_id[similar_word]
                        print(f"   üîó Similar: {similar_word} ‚Üí ID {similar_id}")
                        
                        # Create unique key for relationship
                        source_id = min(target_id, similar_id)
                        target_id_rel = max(target_id, similar_id)
                        
                        relationship_key = f"{source_id}-{target_id_rel}"
                        
                        # Only add if not already processed
                        if relationship_key not in unique_relationships:
                            # SIMPLE similarity data - only source and target IDs
                            similarity_data = {
                                'source_word_id': source_id,
                                'target_word_id': target_id_rel
                            }
                            
                            unique_relationships.add(relationship_key)
                            total_relationships += 1
                            
                            # Insert immediately into NEW table only
                            try:
                                result = supabase.table('word_similarities').upsert(
                                    similarity_data,
                                    on_conflict='source_word_id,target_word_id'
                                ).execute()
                                
                                print(f"   ‚úÖ Created: {source_id} ‚Üí {target_id_rel}")
                                    
                            except Exception as e:
                                print(f"   ‚ùå Error inserting relationship: {e}")
                                error_count += 1
                    
                    processed_count += 1
                    print(f"üìä Processed {processed_count} French words, {total_relationships} relationships\n")
                    
                    # Stop after processing a few examples to show the pattern
                    if processed_count >= 5:
                        print("üõë Stopping after 5 examples to show the mapping pattern...")
                        break
                        
                except Exception as e:
                    print(f"‚ùå Error processing row {processed_count}: {e}")
                    error_count += 1
                    continue
        
        print("\n" + "=" * 60)
        print("üéâ Simple word similarity migration completed!")
        print(f"üìä Summary:")
        print(f"   ‚úÖ Processed {processed_count} French target words")
        print(f"   ‚ö†Ô∏è  Skipped {skipped_count} words not in French vocabulary")
        print(f"   ‚ùå Errors: {error_count}")
        print(f"   üîó Total unique relationships created: {total_relationships}")
        
        # Calculate success rate
        success_rate = (processed_count / (processed_count + skipped_count) * 100) if (processed_count + skipped_count) > 0 else 0
        print(f"   üìà Success rate: {success_rate:.1f}%")
        
        # Verify migration results
        print(f"\nüîç Verifying migration results...")
        verify_result = supabase.table('word_similarities').select('*', count='exact').execute()
        if verify_result.count:
            print(f"   üìà Total word similarity relationships: {verify_result.count}")
        
        print(f"\nüîí SAFETY CONFIRMATION:")
        print(f"   ‚úÖ No existing vocabulary data was modified")
        print(f"   ‚úÖ No existing deck data was modified")
        print(f"   ‚úÖ No existing user progress was modified")
        print(f"   ‚úÖ Only NEW relationships were added to word_similarities table")
        print(f"   ‚úÖ SIMPLE structure: only source_word_id and target_word_id")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Fatal error during migration: {e}")
        return False

if __name__ == "__main__":
    success = migrate_simple_word_mapping()
    if success:
        print("\nüöÄ Ready to continue with full migration!")
        print("üí° This shows the SIMPLE approach with only source and target word IDs.")
        print("üîÑ Run with full processing to migrate all word similarities.")
        print("üîí Your existing data remains completely unchanged!")
    else:
        print("\nüîß Please fix errors before proceeding.")
