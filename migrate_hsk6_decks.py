#!/usr/bin/env python3
"""
HSK6 Vocabulary Migration Script
Migrates 5 merged HSK6 vocabulary databases to Supabase
Converts traditional Chinese to simplified Chinese
"""

import sqlite3
import json
import os
from pathlib import Path
from supabase import create_client, Client
from dotenv import load_dotenv
import time
from typing import List, Dict, Any
import re

# Load environment variables
print("Loading environment variables...")
load_dotenv('.env.local')

# Initialize Supabase client
supabase_url = os.getenv('NEXT_PUBLIC_SUPABASE_URL')
supabase_key = os.getenv('NEXT_PUBLIC_SUPABASE_ANON_KEY')

print(f"Supabase URL: {supabase_url}")
print(f"Supabase Key: {supabase_key[:20]}..." if supabase_key else "None")

if not supabase_url or not supabase_key:
    raise ValueError("Missing Supabase environment variables")

print("Creating Supabase client...")
supabase: Client = create_client(supabase_url, supabase_key)

# HSK6 vocabulary database path
HSK6_VOCAB_PATH = "/Users/ding/Desktop/Coding/Chinese App"

# Traditional to Simplified Chinese mapping (common HSK6 terms)
TRADITIONAL_TO_SIMPLIFIED = {
    # Common HSK6 vocabulary that might contain traditional characters
    'Â≠∏Áøí': 'Â≠¶‰π†',
    'Â≠∏Ê†°': 'Â≠¶Ê†°',
    'Â≠∏Áîü': 'Â≠¶Áîü',
    'ËÄÅÂ∏´': 'ËÄÅÂ∏à',
    'Ë™≤Á®ã': 'ËØæÁ®ã',
    'ËÄÉË©¶': 'ËÄÉËØï',
    'ÊàêÁ∏æ': 'ÊàêÁª©',
    'Áï¢Ê•≠': 'ÊØï‰∏ö',
    'Â§ßÂ≠∏': 'Â§ßÂ≠¶',
    '‰∏≠Â≠∏': '‰∏≠Â≠¶',
    'Â∞èÂ≠∏': 'Â∞èÂ≠¶',
    'ÂúñÊõ∏È§®': 'Âõæ‰π¶È¶Ü',
    'ÂØ¶È©óÂÆ§': 'ÂÆûÈ™åÂÆ§',
    'Ëæ¶ÂÖ¨ÂÆ§': 'ÂäûÂÖ¨ÂÆ§',
    'ÊúÉË≠∞ÂÆ§': '‰ºöËÆÆÂÆ§',
    'È§êÂª≥': 'È§êÂéÖ',
    'ÈÜ´Èô¢': 'ÂåªÈô¢',
    'ÈäÄË°å': 'Èì∂Ë°å',
    'ÈÉµÂ±Ä': 'ÈÇÆÂ±Ä',
    'Ë≠¶ÂØüÂ±Ä': 'Ë≠¶ÂØüÂ±Ä',
    'ÁÅ´ËªäÁ´ô': 'ÁÅ´ËΩ¶Á´ô',
    'È£õÊ©üÂ†¥': 'È£ûÊú∫Âú∫',
    'Âú∞ÈêµÁ´ô': 'Âú∞ÈìÅÁ´ô',
    'ÂÖ¨ÂÖ±Ê±ΩËªä': 'ÂÖ¨ÂÖ±Ê±ΩËΩ¶',
    'Ë®àÁ®ãËªä': 'ËÆ°Á®ãËΩ¶',
    'Ëá™Ë°åËªä': 'Ëá™Ë°åËΩ¶',
    'Êë©ÊâòËªä': 'Êë©ÊâòËΩ¶',
    'ÈõªÊ¢Ø': 'ÁîµÊ¢Ø',
    'Ê®ìÊ¢Ø': 'Ê•ºÊ¢Ø',
    'ÈõªÁáà': 'ÁîµÁÅØ',
    'ÈõªË¶ñ': 'ÁîµËßÜ',
    'ÈõªËÖ¶': 'ÁîµËÑë',
    'ÈõªË©±': 'ÁîµËØù',
    'ÊâãÊ©ü': 'ÊâãÊú∫',
    'Áõ∏Ê©ü': 'Áõ∏Êú∫',
    'Êî∂Èü≥Ê©ü': 'Êî∂Èü≥Êú∫',
    'ÈåÑÈü≥Ê©ü': 'ÂΩïÈü≥Êú∫',
    'ÁÖßÁõ∏Ê©ü': 'ÁÖßÁõ∏Êú∫',
    'ÈõªÂΩ±Èô¢': 'ÁîµÂΩ±Èô¢',
    'ÂäáÈô¢': 'ÂâßÈô¢',
    'ÂçöÁâ©È§®': 'ÂçöÁâ©È¶Ü',
    'ÁæéË°ìÈ§®': 'ÁæéÊúØÈ¶Ü',
    'ÂÖ¨Âúí': 'ÂÖ¨Âõ≠',
    'ÂãïÁâ©Âúí': 'Âä®Áâ©Âõ≠',
    'Ê§çÁâ©Âúí': 'Ê§çÁâ©Âõ≠',
    'ÈÅäÊ®ÇÂúí': 'Ê∏∏‰πêÂõ≠',
    'Ê∏∏Ê≥≥Ê±†': 'Ê∏∏Ê≥≥Ê±†',
    'ÂÅ•Ë∫´Êàø': 'ÂÅ•Ë∫´Êàø',
    'È´îËÇ≤È§®': '‰ΩìËÇ≤È¶Ü',
    'Ë∂≥ÁêÉÂ†¥': 'Ë∂≥ÁêÉÂú∫',
    'Á±ÉÁêÉÂ†¥': 'ÁØÆÁêÉÂú∫',
    'Á∂≤ÁêÉÂ†¥': 'ÁΩëÁêÉÂú∫',
    'È´òÁàæÂ§´ÁêÉÂ†¥': 'È´òÂ∞îÂ§´ÁêÉÂú∫',
    'ÊªëÈõ™Â†¥': 'ÊªëÈõ™Âú∫',
    'Êµ∑ÁÅò': 'Êµ∑Êª©',
    'Â±±ËÑà': 'Â±±ËÑâ',
    'Ê≤≥ÊµÅ': 'Ê≤≥ÊµÅ',
    'ÊπñÊ≥ä': 'ÊπñÊ≥ä',
    'Êµ∑Ê¥ã': 'Êµ∑Ê¥ã',
    'Â≥∂Â∂º': 'Â≤õÂ±ø',
    'Ê£ÆÊûó': 'Ê£ÆÊûó',
    'Ê≤ôÊº†': 'Ê≤ôÊº†',
    'ËçâÂéü': 'ËçâÂéü',
    'Ëæ≤Áî∞': 'ÂÜúÁî∞',
    'ÊûúÂúí': 'ÊûúÂõ≠',
    'Ëä±Âúí': 'Ëä±Âõ≠',
    'ËèúÂúí': 'ËèúÂõ≠',
    'Ê∫´ÂÆ§': 'Ê∏©ÂÆ§',
    'Ëæ≤Â†¥': 'ÂÜúÂú∫',
    'ÁâßÂ†¥': 'ÁâßÂú∫',
    'ÊºÅÂ†¥': 'Ê∏îÂú∫',
    'Á§¶Â†¥': 'ÁüøÂú∫',
    'Â∑•Âª†': 'Â∑•ÂéÇ',
    'ËªäÈñì': 'ËΩ¶Èó¥',
    'ÂÄâÂ∫´': '‰ªìÂ∫ì',
    'ÂïÜÂ∫ó': 'ÂïÜÂ∫ó',
    'Ë∂ÖÂ∏Ç': 'Ë∂ÖÂ∏Ç',
    'Â∏ÇÂ†¥': 'Â∏ÇÂú∫',
    'ÂïÜÂ†¥': 'ÂïÜÂú∫',
    'ÁôæË≤®ÂÖ¨Âè∏': 'ÁôæË¥ßÂÖ¨Âè∏',
    'Â∞àË≥£Â∫ó': '‰∏ìÂçñÂ∫ó',
    '‰æøÂà©Â∫ó': '‰æøÂà©Â∫ó',
    'Êõ∏Â∫ó': '‰π¶Â∫ó',
    'ÊñáÂÖ∑Â∫ó': 'ÊñáÂÖ∑Â∫ó',
    'ÊúçË£ùÂ∫ó': 'ÊúçË£ÖÂ∫ó',
    'ÈûãÂ∫ó': 'ÈûãÂ∫ó',
    'Áè†ÂØ∂Â∫ó': 'Áè†ÂÆùÂ∫ó',
    'ÂåñÂ¶ùÂìÅÂ∫ó': 'ÂåñÂ¶ÜÂìÅÂ∫ó',
    'Ëó•Â∫ó': 'ËçØÂ∫ó',
    'ÁúºÈè°Â∫ó': 'ÁúºÈïúÂ∫ó',
    'ÁêÜÈ´ÆÂ∫ó': 'ÁêÜÂèëÂ∫ó',
    'ÁæéÂÆπÈô¢': 'ÁæéÂÆπÈô¢',
    'ÊåâÊë©Èô¢': 'ÊåâÊë©Èô¢',
    'Áëú‰ºΩÈ§®': 'Áëú‰ºΩÈ¶Ü',
    'Ê≠¶Ë°ìÈ§®': 'Ê≠¶ÊúØÈ¶Ü',
    'ËàûËπàÂ≠∏Ê†°': 'ËàûËπàÂ≠¶Ê†°',
    'Èü≥Ê®ÇÂ≠∏Ê†°': 'Èü≥‰πêÂ≠¶Ê†°',
    'ÁæéË°ìÂ≠∏Ê†°': 'ÁæéÊúØÂ≠¶Ê†°',
    'Ë™ûË®ÄÂ≠∏Ê†°': 'ËØ≠Ë®ÄÂ≠¶Ê†°',
    'ÈßïÈßõÂ≠∏Ê†°': 'È©æÈ©∂Â≠¶Ê†°',
    'ÁÉπÈ£™Â≠∏Ê†°': 'ÁÉπÈ•™Â≠¶Ê†°',
    'ÈõªËÖ¶Â≠∏Ê†°': 'ÁîµËÑëÂ≠¶Ê†°',
    'ÊúÉË®àÂ∏´‰∫ãÂãôÊâÄ': '‰ºöËÆ°Â∏à‰∫ãÂä°ÊâÄ',
    'ÂæãÂ∏´‰∫ãÂãôÊâÄ': 'ÂæãÂ∏à‰∫ãÂä°ÊâÄ',
    'Âª∫ÁØâÂ∏´‰∫ãÂãôÊâÄ': 'Âª∫Á≠ëÂ∏à‰∫ãÂä°ÊâÄ',
    'Â∑•Á®ãÂ∏´‰∫ãÂãôÊâÄ': 'Â∑•Á®ãÂ∏à‰∫ãÂä°ÊâÄ',
    'Ë®≠Ë®àÂ∏´‰∫ãÂãôÊâÄ': 'ËÆæËÆ°Â∏à‰∫ãÂä°ÊâÄ',
    'ÁøªË≠ØÂÖ¨Âè∏': 'ÁøªËØëÂÖ¨Âè∏',
    'Âª£ÂëäÂÖ¨Âè∏': 'ÂπøÂëäÂÖ¨Âè∏',
    'ÂÖ¨ÈóúÂÖ¨Âè∏': 'ÂÖ¨ÂÖ≥ÂÖ¨Âè∏',
    'Ë´ÆË©¢ÂÖ¨Âè∏': 'Âí®ËØ¢ÂÖ¨Âè∏',
    'ÊäïË≥áÂÖ¨Âè∏': 'ÊäïËµÑÂÖ¨Âè∏',
    '‰øùÈö™ÂÖ¨Âè∏': '‰øùÈô©ÂÖ¨Âè∏',
    'ÊàøÂú∞Áî¢ÂÖ¨Âè∏': 'ÊàøÂú∞‰∫ßÂÖ¨Âè∏',
    'ÊóÖÈÅäÂÖ¨Âè∏': 'ÊóÖÊ∏∏ÂÖ¨Âè∏',
    'ÈÅãËº∏ÂÖ¨Âè∏': 'ËøêËæìÂÖ¨Âè∏',
    'Áâ©ÊµÅÂÖ¨Âè∏': 'Áâ©ÊµÅÂÖ¨Âè∏',
    'Âø´ÈÅûÂÖ¨Âè∏': 'Âø´ÈÄíÂÖ¨Âè∏',
    'Ê∏ÖÊΩîÂÖ¨Âè∏': 'Ê∏ÖÊ¥ÅÂÖ¨Âè∏',
    '‰øùÂÆâÂÖ¨Âè∏': '‰øùÂÆâÂÖ¨Âè∏',
    'Á∂≠‰øÆÂÖ¨Âè∏': 'Áª¥‰øÆÂÖ¨Âè∏',
    'ÂÆâË£ùÂÖ¨Âè∏': 'ÂÆâË£ÖÂÖ¨Âè∏',
    'Ë£ù‰øÆÂÖ¨Âè∏': 'Ë£Ö‰øÆÂÖ¨Âè∏',
    'Âª∫ÁØâÂÖ¨Âè∏': 'Âª∫Á≠ëÂÖ¨Âè∏',
    'ÈñãÁôºÂÖ¨Âè∏': 'ÂºÄÂèëÂÖ¨Âè∏',
    'Ë£ΩÈÄ†ÂÖ¨Âè∏': 'Âà∂ÈÄ†ÂÖ¨Âè∏',
    'Ë≤øÊòìÂÖ¨Âè∏': 'Ë¥∏ÊòìÂÖ¨Âè∏',
    'ÈÄ≤Âá∫Âè£ÂÖ¨Âè∏': 'ËøõÂá∫Âè£ÂÖ¨Âè∏',
    'ÊâπÁôºÂÖ¨Âè∏': 'ÊâπÂèëÂÖ¨Âè∏',
    'Èõ∂ÂîÆÂÖ¨Âè∏': 'Èõ∂ÂîÆÂÖ¨Âè∏',
    'ÈÄ£ÈéñÂ∫ó': 'ËøûÈîÅÂ∫ó',
    'Âä†ÁõüÂ∫ó': 'Âä†ÁõüÂ∫ó',
    'Áõ¥ÁáüÂ∫ó': 'Áõ¥Ëê•Â∫ó',
    'Á∂≤Â∫ó': 'ÁΩëÂ∫ó',
    'ÂØ¶È´îÂ∫ó': 'ÂÆû‰ΩìÂ∫ó',
    'ÊóóËâ¶Â∫ó': 'ÊóóËà∞Â∫ó',
    'Ê¶ÇÂøµÂ∫ó': 'Ê¶ÇÂøµÂ∫ó',
    'È´îÈ©óÂ∫ó': '‰ΩìÈ™åÂ∫ó',
    'Â±ïÁ§∫Âª≥': 'Â±ïÁ§∫ÂéÖ',
    'Â±ïË¶ΩÈ§®': 'Â±ïËßàÈ¶Ü',
    'ÊúÉË≠∞‰∏≠ÂøÉ': '‰ºöËÆÆ‰∏≠ÂøÉ',
    'Â±ïË¶Ω‰∏≠ÂøÉ': 'Â±ïËßà‰∏≠ÂøÉ',
    'ÂïÜÂãô‰∏≠ÂøÉ': 'ÂïÜÂä°‰∏≠ÂøÉ',
    'ÈáëËûç‰∏≠ÂøÉ': 'ÈáëËûç‰∏≠ÂøÉ',
    'ÊñáÂåñ‰∏≠ÂøÉ': 'ÊñáÂåñ‰∏≠ÂøÉ',
    'ËóùË°ì‰∏≠ÂøÉ': 'Ëâ∫ÊúØ‰∏≠ÂøÉ',
    'ÁßëÊäÄ‰∏≠ÂøÉ': 'ÁßëÊäÄ‰∏≠ÂøÉ',
    'ÊïôËÇ≤‰∏≠ÂøÉ': 'ÊïôËÇ≤‰∏≠ÂøÉ',
    'ÂüπË®ì‰∏≠ÂøÉ': 'ÂüπËÆ≠‰∏≠ÂøÉ',
    'Á†îÁ©∂‰∏≠ÂøÉ': 'Á†îÁ©∂‰∏≠ÂøÉ',
    'ÈñãÁôº‰∏≠ÂøÉ': 'ÂºÄÂèë‰∏≠ÂøÉ',
    'ÂâµÊñ∞‰∏≠ÂøÉ': 'ÂàõÊñ∞‰∏≠ÂøÉ',
    'ÂâµÊ•≠‰∏≠ÂøÉ': 'Âàõ‰∏ö‰∏≠ÂøÉ',
    'Â≠µÂåñÂô®': 'Â≠µÂåñÂô®',
    'Âä†ÈÄüÂô®': 'Âä†ÈÄüÂô®',
    'ÁßëÊäÄÂúí': 'ÁßëÊäÄÂõ≠',
    'Â∑•Ê•≠Âúí': 'Â∑•‰∏öÂõ≠',
    'Á∂ìÊøüÈñãÁôºÂçÄ': 'ÁªèÊµéÂºÄÂèëÂå∫',
    'Ëá™Áî±Ë≤øÊòìÂçÄ': 'Ëá™Áî±Ë¥∏ÊòìÂå∫',
    '‰øùÁ®ÖÂçÄ': '‰øùÁ®éÂå∫',
    'Âá∫Âè£Âä†Â∑•ÂçÄ': 'Âá∫Âè£Âä†Â∑•Âå∫',
    'È´òÊñ∞ÊäÄË°ìÈñãÁôºÂçÄ': 'È´òÊñ∞ÊäÄÊúØÂºÄÂèëÂå∫',
    'Á∂ìÊøüÁâπÂçÄ': 'ÁªèÊµéÁâπÂå∫',
    'Ê≤øÊµ∑ÈñãÊîæÂüéÂ∏Ç': 'Ê≤øÊµ∑ÂºÄÊîæÂüéÂ∏Ç',
    'ÂÖßÈô∏ÈñãÊîæÂüéÂ∏Ç': 'ÂÜÖÈôÜÂºÄÊîæÂüéÂ∏Ç',
    'ÈÇäÂ¢ÉÈñãÊîæÂüéÂ∏Ç': 'ËæπÂ¢ÉÂºÄÊîæÂüéÂ∏Ç',
    '‰∏ÄÂ∏∂‰∏ÄË∑Ø': '‰∏ÄÂ∏¶‰∏ÄË∑Ø',
    'Áµ≤Á∂¢‰πãË∑Ø': '‰∏ùÁª∏‰πãË∑Ø',
    'Êµ∑‰∏äÁµ≤Á∂¢‰πãË∑Ø': 'Êµ∑‰∏ä‰∏ùÁª∏‰πãË∑Ø',
    'Èô∏‰∏äÁµ≤Á∂¢‰πãË∑Ø': 'ÈôÜ‰∏ä‰∏ùÁª∏‰πãË∑Ø',
    'Êï∏Â≠óÁµ≤Á∂¢‰πãË∑Ø': 'Êï∞Â≠ó‰∏ùÁª∏‰πãË∑Ø',
    'ÂÅ•Â∫∑Áµ≤Á∂¢‰πãË∑Ø': 'ÂÅ•Â∫∑‰∏ùÁª∏‰πãË∑Ø',
    'Á∂†Ëâ≤Áµ≤Á∂¢‰πãË∑Ø': 'ÁªøËâ≤‰∏ùÁª∏‰πãË∑Ø',
    'ÂâµÊñ∞Áµ≤Á∂¢‰πãË∑Ø': 'ÂàõÊñ∞‰∏ùÁª∏‰πãË∑Ø',
    'ÊñáÊòéÁµ≤Á∂¢‰πãË∑Ø': 'ÊñáÊòé‰∏ùÁª∏‰πãË∑Ø',
    'ÂíåÂπ≥Áµ≤Á∂¢‰πãË∑Ø': 'ÂíåÂπ≥‰∏ùÁª∏‰πãË∑Ø',
    'ÁπÅÊ¶ÆÁµ≤Á∂¢‰πãË∑Ø': 'ÁπÅËç£‰∏ùÁª∏‰πãË∑Ø',
    'ÈñãÊîæÁµ≤Á∂¢‰πãË∑Ø': 'ÂºÄÊîæ‰∏ùÁª∏‰πãË∑Ø',
    'ÂåÖÂÆπÁµ≤Á∂¢‰πãË∑Ø': 'ÂåÖÂÆπ‰∏ùÁª∏‰πãË∑Ø',
    'Âπ≥Ë°°Áµ≤Á∂¢‰πãË∑Ø': 'Âπ≥Ë°°‰∏ùÁª∏‰πãË∑Ø',
    'ÊôÆÊÉ†Áµ≤Á∂¢‰πãË∑Ø': 'ÊôÆÊÉ†‰∏ùÁª∏‰πãË∑Ø',
    'ÂèØÊåÅÁ∫åÁµ≤Á∂¢‰πãË∑Ø': 'ÂèØÊåÅÁª≠‰∏ùÁª∏‰πãË∑Ø',
    'È´òË≥™ÈáèÁµ≤Á∂¢‰πãË∑Ø': 'È´òË¥®Èáè‰∏ùÁª∏‰πãË∑Ø',
    'Áèæ‰ª£ÂåñÁµ≤Á∂¢‰πãË∑Ø': 'Áé∞‰ª£Âåñ‰∏ùÁª∏‰πãË∑Ø',
    'ÂúãÈöõÂåñÁµ≤Á∂¢‰πãË∑Ø': 'ÂõΩÈôÖÂåñ‰∏ùÁª∏‰πãË∑Ø',
    'ÂÖ®ÁêÉÂåñÁµ≤Á∂¢‰πãË∑Ø': 'ÂÖ®ÁêÉÂåñ‰∏ùÁª∏‰πãË∑Ø',
    'ÂçÄÂüüÂåñÁµ≤Á∂¢‰πãË∑Ø': 'Âå∫ÂüüÂåñ‰∏ùÁª∏‰πãË∑Ø',
    '‰∏ÄÈ´îÂåñÁµ≤Á∂¢‰πãË∑Ø': '‰∏Ä‰ΩìÂåñ‰∏ùÁª∏‰πãË∑Ø',
    'Â§öÂÖÉÂåñÁµ≤Á∂¢‰πãË∑Ø': 'Â§öÂÖÉÂåñ‰∏ùÁª∏‰πãË∑Ø',
    'Á´ãÈ´îÂåñÁµ≤Á∂¢‰πãË∑Ø': 'Á´ã‰ΩìÂåñ‰∏ùÁª∏‰πãË∑Ø',
    'Á∂≤Áµ°ÂåñÁµ≤Á∂¢‰πãË∑Ø': 'ÁΩëÁªúÂåñ‰∏ùÁª∏‰πãË∑Ø',
    'Êô∫ËÉΩÂåñÁµ≤Á∂¢‰πãË∑Ø': 'Êô∫ËÉΩÂåñ‰∏ùÁª∏‰πãË∑Ø',
    'Êï∏Â≠óÂåñÁµ≤Á∂¢‰πãË∑Ø': 'Êï∞Â≠óÂåñ‰∏ùÁª∏‰πãË∑Ø',
    '‰ø°ÊÅØÂåñÁµ≤Á∂¢‰πãË∑Ø': '‰ø°ÊÅØÂåñ‰∏ùÁª∏‰πãË∑Ø'
}

def convert_to_simplified_chinese(text: str) -> str:
    """Convert traditional Chinese characters to simplified Chinese"""
    if not text:
        return text
    
    result = text
    for traditional, simplified in TRADITIONAL_TO_SIMPLIFIED.items():
        result = result.replace(traditional, simplified)
    
    return result

def create_hsk6_decks() -> List[Dict[str, Any]]:
    """Create the 5 HSK6 vocabulary decks"""
    decks = [
        {
            "name": "HSK6 Level 1",
            "description": "HSK6 vocabulary - Part 1 (Advanced Chinese)",
            "difficulty_level": "advanced",
            "language_a_name": "Chinese",
            "language_b_name": "French",
            "language_a_code": "zh",
            "language_b_code": "fr",
            "total_words": 1003,
            "is_active": True
        },
        {
            "name": "HSK6 Level 2", 
            "description": "HSK6 vocabulary - Part 2 (Advanced Chinese)",
            "difficulty_level": "advanced",
            "language_a_name": "Chinese",
            "language_b_name": "French", 
            "language_a_code": "zh",
            "language_b_code": "fr",
            "total_words": 1003,
            "is_active": True
        },
        {
            "name": "HSK6 Level 3",
            "description": "HSK6 vocabulary - Part 3 (Advanced Chinese)", 
            "difficulty_level": "advanced",
            "language_a_name": "Chinese",
            "language_b_name": "French",
            "language_a_code": "zh", 
            "language_b_code": "fr",
            "total_words": 1003,
            "is_active": True
        },
        {
            "name": "HSK6 Level 4",
            "description": "HSK6 vocabulary - Part 4 (Advanced Chinese)",
            "difficulty_level": "advanced", 
            "language_a_name": "Chinese",
            "language_b_name": "French",
            "language_a_code": "zh",
            "language_b_code": "fr",
            "total_words": 1002,
            "is_active": True
        },
        {
            "name": "HSK6 Level 5",
            "description": "HSK6 vocabulary - Part 5 (Advanced Chinese)",
            "difficulty_level": "advanced",
            "language_a_name": "Chinese", 
            "language_b_name": "French",
            "language_a_code": "zh",
            "language_b_code": "fr",
            "total_words": 1002,
            "is_active": True
        }
    ]
    return decks

def load_vocabulary_from_db(db_path: str) -> List[Dict[str, Any]]:
    """Load vocabulary from SQLite database"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT word_number, chinese_word, french_translation, 
               example_sentence, sentence_translation
        FROM vocabulary
        ORDER BY word_number
    """)
    
    rows = cursor.fetchall()
    conn.close()
    
    vocabulary = []
    for row in rows:
        word_number, chinese_word, french_translation, example_sentence, sentence_translation = row
        
        # Convert traditional Chinese to simplified
        chinese_word_simplified = convert_to_simplified_chinese(chinese_word)
        example_sentence_simplified = convert_to_simplified_chinese(example_sentence)
        
        vocabulary.append({
            "word_number": word_number,
            "language_a_word": chinese_word_simplified,
            "language_b_translation": french_translation,
            "language_a_sentence": example_sentence_simplified,
            "language_b_sentence": sentence_translation
        })
    
    return vocabulary

def insert_deck_to_supabase(deck: Dict[str, Any]) -> str:
    """Insert deck into Supabase and return deck ID"""
    try:
        result = supabase.table('vocabulary_decks').insert(deck).execute()
        deck_id = result.data[0]['id']
        print(f"‚úÖ Created deck: {deck['name']} (ID: {deck_id})")
        return deck_id
    except Exception as e:
        print(f"‚ùå Error creating deck {deck['name']}: {e}")
        raise

def insert_vocabulary_to_supabase(vocabulary: List[Dict[str, Any]]) -> List[str]:
    """Insert vocabulary into Supabase and return vocabulary IDs"""
    vocab_ids = []
    
    # Insert in batches of 100
    batch_size = 100
    for i in range(0, len(vocabulary), batch_size):
        batch = vocabulary[i:i + batch_size]
        
        # Prepare batch data
        batch_data = []
        for item in batch:
            batch_data.append({
                "language_a_word": item["language_a_word"],
                "language_b_translation": item["language_b_translation"],
                "language_a_sentence": item["language_a_sentence"],
                "language_b_sentence": item["language_b_sentence"]
            })
        
        try:
            result = supabase.table('vocabulary').insert(batch_data).execute()
            batch_ids = [item['id'] for item in result.data]
            vocab_ids.extend(batch_ids)
            print(f"‚úÖ Inserted batch {i//batch_size + 1}: {len(batch_ids)} words")
        except Exception as e:
            print(f"‚ùå Error inserting vocabulary batch {i//batch_size + 1}: {e}")
            raise
    
    return vocab_ids

def link_vocabulary_to_deck(deck_id: str, vocabulary_ids: List[str]):
    """Link vocabulary to deck in deck_vocabulary table"""
    deck_vocab_data = []
    for i, vocab_id in enumerate(vocabulary_ids):
        deck_vocab_data.append({
            "deck_id": deck_id,
            "vocabulary_id": vocab_id,
            "word_order": i + 1
        })
    
    # Insert in batches
    batch_size = 100
    for i in range(0, len(deck_vocab_data), batch_size):
        batch = deck_vocab_data[i:i + batch_size]
        
        try:
            supabase.table('deck_vocabulary').insert(batch).execute()
            print(f"‚úÖ Linked batch {i//batch_size + 1}: {len(batch)} words to deck")
        except Exception as e:
            print(f"‚ùå Error linking vocabulary batch {i//batch_size + 1}: {e}")
            raise

def migrate_hsk6_decks():
    """Main migration function"""
    print("üöÄ Starting HSK6 Vocabulary Migration")
    print("=" * 60)
    
    # Create decks
    decks = create_hsk6_decks()
    deck_ids = []
    
    for i, deck in enumerate(decks, 1):
        print(f"\nüìö Processing Deck {i}: {deck['name']}")
        print("-" * 40)
        
        # Create deck in Supabase
        deck_id = insert_deck_to_supabase(deck)
        deck_ids.append(deck_id)
        
        # Load vocabulary from SQLite
        db_path = f"{HSK6_VOCAB_PATH}/hsk6_vocab_batch_merged_{i}.db"
        print(f"üìñ Loading vocabulary from: {db_path}")
        
        vocabulary = load_vocabulary_from_db(db_path)
        print(f"üìù Loaded {len(vocabulary)} vocabulary items")
        
        # Show sample of converted text
        if vocabulary:
            sample = vocabulary[0]
            print(f"üîç Sample conversion:")
            print(f"   Chinese: {sample['language_a_word']}")
            print(f"   French: {sample['language_b_translation']}")
            print(f"   Example: {sample['language_a_sentence'][:50]}...")
        
        # Insert vocabulary to Supabase
        print(f"üíæ Inserting vocabulary to Supabase...")
        vocabulary_ids = insert_vocabulary_to_supabase(vocabulary)
        
        # Link vocabulary to deck
        print(f"üîó Linking vocabulary to deck...")
        link_vocabulary_to_deck(deck_id, vocabulary_ids)
        
        print(f"‚úÖ Completed Deck {i}: {deck['name']}")
        
        # Small delay between decks
        if i < len(decks):
            time.sleep(1)
    
    print("\n" + "=" * 60)
    print("üéâ HSK6 Vocabulary Migration Complete!")
    print(f"üìä Created {len(deck_ids)} decks with total vocabulary items")
    
    return deck_ids

if __name__ == "__main__":
    try:
        deck_ids = migrate_hsk6_decks()
        print(f"\nüéØ Deck IDs created: {deck_ids}")
    except Exception as e:
        print(f"‚ùå Migration failed: {e}")
        raise
